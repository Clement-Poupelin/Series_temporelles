{
  "hash": "26c801028297c2b6a6d8537e7c795f19",
  "result": {
    "markdown": "---\ntitle: \"Fiche 06 : Bootstrap\"\nauthor: \"Clément Poupelin\"\ndate: \"2025-02-xx\"\ndate-modified: \"2025-02-27\"\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"categorie 1\", \"cotegorie 2\"]\nimage: \"\"\ndescription: \"Description\"\n---\n\n\n# Intervenant.e.s\n\n### Rédaction\n\n-   **Clément Poupelin**, [clementjc.poupelin\\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\\\n\n### Relecture\n\n-   \n\n# Setup\n\n:::: panel-tabset\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Données\nlibrary(dplyr)        # manipulation des données\n\n\n# Plots\n## ggplot\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\n## Fonctions\n\n::: panel-tabset\n### Fonction 1\n\n### Fonction 2\n:::\n\n## Seed\n::::\n\n# Données\n\n# Analyse\n\n::: callout-note\nMETTRE LES REMARQUES\n:::\n\n::: callout-warning\nMETTRE LES POINTS D'ATTENTION\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nMETTRE LES CONCLUSIONS\n:::\n\n# Conclusion\n\n# Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(pkgs = \"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 22631)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  French_France.utf8\n ctype    French_France.utf8\n tz       Europe/Paris\n date     2025-02-27\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package   * version date (UTC) lib source\n dplyr     * 1.1.4   2023-11-17 [1] CRAN (R 4.2.3)\n ggplot2   * 3.5.1   2024-04-23 [1] CRAN (R 4.2.3)\n gridExtra * 2.3     2017-09-09 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/cleme/AppData/Local/R/win-library/4.2\n [2] C:/Program Files/R/R-4.2.1/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n\n\n\nOn considère le modèle\n\\begin{align}\nx_t = \\mu + \\phi(x_{t-1} - \\mu) + w_t\n\\end{align}\n\n\n$\\longrightarrow$ Les valeurs des paramètres sont $\\mu = 50$ et $\\phi = .95$\n\n$\\longrightarrow$ On dispose d’un échantillon de longueur $n = 100$.\n\n$\\longrightarrow$ **Hypothèse sur le bruit** : la suite $(w_t)_t$ est une suite de va iid suivant la loi double exponentielle, c’est à dire la loi de densité\n\\begin{align}\nf(x) = \\frac{1}{4}e^{-\\frac{|x|}{2}}\n\\end{align}\n\n\n\nOn estime le paramètre $\\phi$ par l’estimateur de Yule Walker $\\hat{\\phi}_n$. On peut calculer cet\nestimateur à l’aide de la fonction **ar.yw**.\n\n\n### QUESTION 1 : Mettre en oeuvre un générateur de nombres aléatoires suivant la loi du bruit.\n\n**Indication :** Montrer que $w_1 = XZ −X(1−Z)$ où la loi de $X$ est la loi exponentielle\nde paramètre $\\frac{1}{2}$ et la loi de $Z$ est la loi de Bernoulli de paramètre $\\frac{1}{2}$. $X$ et $Z$ sont indépendantes.\n\n\n\n\n\n\n\nNous commençons par mettre en oeuvre un générateur de nombres aléatoires suivant la loi du bruit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nW=function(n) {\n  x=rexp(n, 1/2)\n  z=rbinom(n, 1, 1/2)\n  return(x * z - x * (1 - z))\n}\n```\n:::\n\n\n\n### QUESTION 2 : Construire une fonction pour simuler des processus AR(1) suivant le modèle considéré.\n\n (vous pouvez utiliser la fonction **arima.sim**, prendre **n.start = 50** pour supprimer les 50 premières observations )\n \n \nNous voulons maintenant pouvoir simuler un processus AR(1) suivant notre modèle. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimu_ar=function(mu, phi, n) {\n  X=c()\n  X[1] = W(1)\n  for (i in 2:(n + 50)) {\n    X[i] = mu + phi * (X[i - 1] - mu) + W(1)\n  }\n  return(X[51:(n + 50)])\n}\n```\n:::\n\n\n\n### QUESTION 3 : En utilisant une méthode de Monte Carlo construire un échantillon suivant la loi de $\\hat{\\phi}_n - \\phi$ et représenter graphiquement la densité de la loi de $\\hat{\\phi}_n - \\phi$ approchée à partir de cet échantillon.\n\n\nNous souhaitons utiliser une méthode de Monté-Carlo pour construire un échantillon qui suit la loi de $\\hat{\\phi}_n - \\phi$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nombre d'itérations pour notre méthode MC\nnb_iterations = 1000\n\n# Echantillon pour stoccker les \\hat{\\phi}_n - \\phi\nechantillon_phi=rep(0, nb_iterations)\n\n# Matrice pour stocker nos simulations d'où l'on prélèvera le \\phi estimé\nx=matrix(NA,nrow = nb_iterations,ncol=nb_iterations)\n\nfor (i in 1:nb_iterations) {\n  x[i,] = simu_ar(mu, phi, n)\n  \n  # Estimer phi avec Yule-Walker\n  phi_n = ar.yw(x[i,], order = 1)$ar\n  \n  \n  echantillon_phi[i] = phi_n - phi\n}\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](Fiche_06Bootstrap_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n### QUESTION 4 : Simuler votre échantillon d’observations\n\nOn simule un échantillon d'observations. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nechant = simu_ar(mu,phi,n)\n```\n:::\n\n\n### QUESTION 5 : Estimer le paramètre $\\phi$. Représenter graphiquement la densité de l’approximation asymptotique gaussienne de la loi de $\\hat{\\phi}_n - \\phi$\n\nPour cette estimation, on utilise le fait que \n\\begin{align}\n\\hat{\\phi}_n - \\phi \\underset{n\\to +\\infty}{\\longrightarrow} \\mathcal{N}_{(0, \\sigma^2)}\n\\end{align}\n\nPuis, grâce au théorème de Slutsky, on a \n\\begin{align}\n\\frac{\\hat{\\phi}_n - \\phi}{\\hat{\\sigma}} \\underset{n\\to +\\infty}{\\longrightarrow} \\mathcal{N}_{(0, 1)}\\\\\n\\end{align}\n\nOn peut donc estimer $\\sigma^2$ puis utiliser cette estimation pour proposer une représentation de l'approximation asymptotique gaussienne de la loi de $\\hat{\\phi}_n - \\phi$\n\nNous voulons faire une approximation gaussienne de la densité de $\\hat{\\phi}_n - \\phi$. Pour cela, nous estimons $\\phi$ grâce à l'estimateur de Yule Walker. Grâce à cet estimateur, nous avons également une estimation de la variance. Avec cette dernière, nous pouvons alors simuler une loi gaussienne $\\mathcal{N}(0,\\hat\\sigma^2)$ où $\\hat\\sigma^2$\nest l'estimateur de la variance. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nesti = ar.yw(echant, order = 1)\n\nphi_hat = esti$ar # Estimateur de phi\nsigma_hat = sqrt(esti$asy.var.coef) # Estimateur de l'écart type \n```\n:::\n\n\nPour vérifier que l'on a une bonne estimation, nous pouvons comparer à la densité obtenue par Monté-Carlo. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(echantillon_phi, \n  ylab = TeX(\"$phi^n - phi$\"),\n  xlab=\"\",\n  probability = TRUE, \n  col='cyan',\n  main=\"Comparaison des méthodes\")\ncurve(dnorm(x, 0, sigma_hat), add = TRUE, lty = 2, col = \"red\")\n#lines(seq(-.05, .03, length.out=1000),normal, col=\"red\", lty=1)\nlegend(\"topleft\", legend=c(\"Méthode MC\",\"Approximation gaussienne\"),\n       fill=c(\"cyan\",NA),lty=c(0,2),col=c(NA,\"red\"), border=c(\"black\",NA), \n       pch=c(22,NA))\n```\n\n::: {.cell-output-display}\n![](Fiche_06Bootstrap_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### QUESTION 6 : Mettre en oeuvre le bootstrap non paramétrique sur les résidus. A partir de 500 échantillons bootstrappés construire une approximation de la loi de $\\hat{\\phi}_n - \\phi$. Représenter graphiquement l’estimation de la densité de la loi de $\\hat{\\phi}_n - \\phi$\n\n\nLa méthode utilisée est détaillée dans le CM\n\nNous souhaitons mettre en oeuvre un bootstrap non paramétrique sur nos résidus. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Phi estimé\nphi_est = ar.yw(echant, order=1)$ar\n\n# On récupère les résidus pour faire le bootstrap\nres = echant\n\n# Il faut récupérer les résidus \nfor (i in 2:n){\n  res[i] = echant[i]-phi_est*echant[i-1]\n}\n\nn_bootstrap = 500\nphi_hat = numeric(n_bootstrap)\n\nfor (i in 1:n_bootstrap){\n  w_etoile = sample(res, replace=T) # Loi uniforme (def bootstrap)\n  \n  # On simule de nouveau un AR(1) de notre modèle mais avec nos résidus estimés\n  test = arima.sim(list(ar=phi),n=n_bootstrap, innov=w_etoile,n.start=50) + mu \n  \n  # On estime pour faire la représentation graphique \n  phi_hat[i] = ar.yw(test, order=1)$ar - phi \n  \n}\n```\n:::\n\n\nSinon, use le syst dans CM\n\n\\begin{align}\nX_t^* = X_t \nX_{t+1}^* = mu + \\hat{\\phi_n}() + w_t^*\n\n\\end{align}\n\n pour ne pas avoir a faire la boucle de création de résidus et avoir seulement une boucle.\n \n \n\n### QUESTION 7 : Comparer les deux approximations (gaussienne et bootstrap) à la loi calculée par la méthode de Monte Carlo (que l’on peut comme la loi exacte aux approximations numériques près)\n\nNous souhaitons comparer nos différentes méthodes: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(echantillon_phi, \n  ylab = TeX(\"$phi^n - phi$\"),\n  xlab=\"\",\n  probability = TRUE, \n  col='cyan',\n  main=\"Comparaison des méthodes\")\ncurve(dnorm(x, 0, sigma_hat), add = TRUE, lty = 2, col = \"red\")\nlines(density(phi_hat), col='lightgreen', lty=1, lwd = 2 )\nlegend(\"topleft\", legend=c(\"Méthode MC\",\"Approximation gaussienne\", \"Boostrap\"),\n       fill=c(\"cyan\",NA,NA),lty=c(0,1,1),col=c(NA,\"red\",\"lightgreen\"), pch=c(22,NA,NA), border=c(\"black\",NA,NA), lwd = c(0,1,2))\n```\n\n::: {.cell-output-display}\n![](Fiche_06Bootstrap_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### QUESTION 8 : En utilisant vos échantillons bootstrappés donner une approximation de l’intervalle de prévision à l’horizon 1 de niveau 95% .\n\n\nNous voulons, à partir de nos échantillons bootstrappés, donner une approximation de l'intervalle de prévision à l'horizon 1 de niveau 95%. \n\n\nOn reprend notre méthode de bootstrap en ajoutant une étape de prévision \n\n::: {.cell}\n\n```{.r .cell-code}\n# Phi estimé\nphi_est = ar.yw(echant, order=1)$ar\n\n# On récupère les résidus pour faire le bootstrap\nres = echant\n\n# Il faut récupérer les résidus \nfor (i in 2:n){\n  res[i] = echant[i]-phi_est*echant[i-1]\n}\n\nn_bootstrap = 500\nphi_hat = numeric(n_bootstrap)\n\n\nprev = rep(NA, n_bootstrap)\nphi_etoile = rep(NA, n_bootstrap)\n\nfor (i in 1:n_bootstrap){\n  w_etoile = sample(res, replace=T) # Loi uniforme (def bootstrap)\n  \n  # On simule de nouveau un AR(1) de notre modèle mais avec nos résidus estimés\n  test = arima.sim(list(ar=phi), n=n, innov=w_etoile,n.start=50) + mu \n  \n  phi_etoile[i] = ar.yw(test, order=1)$ar\n  \n  # Prévision\n  prev[i] =  phi_etoile[i] *test[n]\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# ecart-type de l'erreur de prévision approximé par bootstrap\nsigma.prev.boot = sd(prev)\n\nprint(paste(\"ecart-type de prévision à h=1 : \", round(sigma.prev.boot, 2))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ecart-type de prévision à h=1 :  9.84\"\n```\n:::\n\n```{.r .cell-code}\n# l'intervalle de prévision approximé par bootstrap\nprev.yw = predict(esti, h=1)\nbornes = as.numeric(prev.yw$pred) - quantile(prev - as.numeric(prev.yw$pred),\n                                             c(0.975, 0.025))\n\nq_inf = bornes[1]\nq_sup = bornes[2]\nprint(paste(\"Intervalle bootstrap de prévision à h=1 : [\", round(q_inf,2), \",\", round(q_sup,2), \"]\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Intervalle bootstrap de prévision à h=1 : [ -81.52 , -44.69 ]\"\n```\n:::\n:::\n\n\n\n\n\n### QUESTION 9 : Mettre en oeuvre le bootstrap stationnaire et donner une approximation de l’intervalle de prévision à l’horizon 1.\n\n\n\n\n\n\n\n\n\n\n\n### QUESTION 10 :  Comparer les résultats obtenus par bootstrap avec l’intervalle théorique de prévision.",
    "supporting": [
      "Fiche_06Bootstrap_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}